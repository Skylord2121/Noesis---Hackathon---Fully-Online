<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Support Call</title>
    <link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }

        body {
            background: linear-gradient(180deg, #1c1c1e 0%, #000000 100%);
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Segoe UI', sans-serif;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: space-between;
            padding: 40px 20px 120px 20px;
            color: white;
            position: relative;
            overflow: hidden;
        }

        /* Blur effect background */
        .blur-bg {
            position: fixed;
            top: -50%;
            left: -50%;
            right: -50%;
            bottom: -50%;
            background: radial-gradient(circle at 50% 50%, rgba(0, 122, 255, 0.15), transparent 60%);
            filter: blur(100px);
            z-index: 0;
            pointer-events: none;
        }

        /* Container */
        .call-container {
            position: relative;
            z-index: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: space-between;
            width: 100%;
            max-width: 400px;
            height: calc(100vh - 80px);
        }

        /* Top Section */
        .call-header {
            text-align: center;
            padding-top: 20px;
        }

        .status-badge {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 6px 16px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            font-size: 13px;
            font-weight: 500;
            margin-bottom: 20px;
        }

        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #30d158;
            box-shadow: 0 0 12px rgba(48, 209, 88, 0.6);
            animation: pulse-dot 2s ease-in-out infinite;
        }

        @keyframes pulse-dot {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.8; transform: scale(1.1); }
        }

        .company-name {
            font-size: 16px;
            font-weight: 600;
            color: rgba(255, 255, 255, 0.6);
            margin-bottom: 10px;
            letter-spacing: 0.5px;
        }

        .call-title {
            font-size: 32px;
            font-weight: 700;
            margin-bottom: 8px;
            letter-spacing: -0.5px;
        }

        .call-subtitle {
            font-size: 17px;
            color: rgba(255, 255, 255, 0.6);
            font-weight: 400;
        }

        .call-timer {
            font-size: 19px;
            color: rgba(255, 255, 255, 0.8);
            margin-top: 15px;
            font-weight: 500;
            font-variant-numeric: tabular-nums;
            letter-spacing: 1px;
        }

        /* Middle Section - Audio Waves */
        .audio-visualization {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 80px;
            margin: 40px 0;
        }

        .audio-bar {
            width: 3px;
            background: rgba(0, 122, 255, 0.6);
            border-radius: 10px;
            transition: height 0.1s ease;
        }

        .audio-bar.active {
            animation: wave 1.2s ease-in-out infinite;
        }

        @keyframes wave {
            0%, 100% { height: 20px; opacity: 0.4; }
            50% { height: 60px; opacity: 1; }
        }

        /* Bottom Section - Controls */
        .call-controls {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 30px;
            width: 100%;
            padding-bottom: 20px;
        }

        .main-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s ease;
            position: relative;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.4);
        }

        .mute-button {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
        }

        .mute-button:active {
            transform: scale(0.95);
            background: rgba(255, 255, 255, 0.25);
        }

        .mute-button.active {
            background: rgba(255, 255, 255, 0.95);
        }

        .mute-button.active i {
            color: #1c1c1e;
        }

        .mute-button i {
            font-size: 28px;
            color: white;
        }

        .hangup-button {
            background: #ff3b30;
            width: 70px;
            height: 70px;
        }

        .hangup-button:active {
            transform: scale(0.95);
            background: #d32f2f;
        }

        .hangup-button i {
            font-size: 32px;
            color: white;
            transform: rotate(135deg);
        }

        .button-label {
            font-size: 13px;
            color: rgba(255, 255, 255, 0.8);
            margin-top: 12px;
            font-weight: 400;
        }

        .control-row {
            display: flex;
            gap: 60px;
            align-items: center;
        }

        .control-item {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        /* Recording pulse effect */
        .mute-button.active::before {
            content: '';
            position: absolute;
            inset: -8px;
            border-radius: 50%;
            background: rgba(0, 122, 255, 0.3);
            animation: pulse-ring 2s ease-out infinite;
        }

        @keyframes pulse-ring {
            0% {
                transform: scale(0.95);
                opacity: 1;
            }
            100% {
                transform: scale(1.3);
                opacity: 0;
            }
        }

        /* Error State */
        .error-message {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(28, 28, 30, 0.95);
            backdrop-filter: blur(30px);
            padding: 30px;
            border-radius: 20px;
            text-align: center;
            max-width: 320px;
            z-index: 100;
        }

        .error-title {
            font-size: 20px;
            font-weight: 700;
            margin-bottom: 10px;
        }

        .error-subtitle {
            font-size: 15px;
            color: rgba(255, 255, 255, 0.6);
            line-height: 1.4;
        }

        /* Mobile optimizations */
        @media (max-width: 400px) {
            .call-title { font-size: 28px; }
            .main-button { width: 75px; height: 75px; }
            .mute-button i { font-size: 26px; }
            .hangup-button { width: 65px; height: 65px; }
            .hangup-button i { font-size: 28px; }
        }

        /* Safe area for notch devices */
        @supports (padding-top: env(safe-area-inset-top)) {
            body {
                padding-top: max(40px, env(safe-area-inset-top));
                padding-bottom: max(120px, calc(120px + env(safe-area-inset-bottom)));
            }
        }
        
        /* Additional mobile bottom padding to avoid navigation bars */
        @media (max-width: 768px) {
            body {
                padding-bottom: 140px;
            }
            
            .call-controls {
                padding-bottom: 40px;
            }
        }
    </style>
</head>
<body>
    <div class="blur-bg"></div>
    
    <div class="call-container">
        <!-- Top Section -->
        <div class="call-header">
            <div class="status-badge">
                <div class="status-dot" id="status-dot"></div>
                <span id="status-text">Connected</span>
            </div>
            
            <div class="company-name">SUPPORT</div>
            <div class="call-title">Customer Service</div>
            <div class="call-subtitle" id="call-subtitle">Tap to speak</div>
            <div class="call-timer" id="call-timer">00:00</div>
        </div>

        <!-- Middle Section - Audio Visualization -->
        <div class="audio-visualization" id="audio-viz">
            <div class="audio-bar" style="animation-delay: 0s;"></div>
            <div class="audio-bar" style="animation-delay: 0.1s;"></div>
            <div class="audio-bar" style="animation-delay: 0.2s;"></div>
            <div class="audio-bar" style="animation-delay: 0.3s;"></div>
            <div class="audio-bar" style="animation-delay: 0.4s;"></div>
            <div class="audio-bar" style="animation-delay: 0.5s;"></div>
            <div class="audio-bar" style="animation-delay: 0.6s;"></div>
            <div class="audio-bar" style="animation-delay: 0.7s;"></div>
            <div class="audio-bar" style="animation-delay: 0.8s;"></div>
            <div class="audio-bar" style="animation-delay: 0.9s;"></div>
            <div class="audio-bar" style="animation-delay: 1.0s;"></div>
            <div class="audio-bar" style="animation-delay: 1.1s;"></div>
        </div>

        <!-- Bottom Section - Controls -->
        <div class="call-controls">
            <div class="control-row">
                <div class="control-item">
                    <button class="main-button mute-button" id="mute-button" onclick="toggleMute()">
                        <i class="fas fa-microphone" id="mute-icon"></i>
                    </button>
                    <div class="button-label" id="mute-label">mute</div>
                </div>
            </div>
            
            <div class="control-item">
                <button class="main-button hangup-button" id="hangup-button" onclick="endCall()">
                    <i class="fas fa-phone"></i>
                </button>
                <div class="button-label">end call</div>
            </div>
        </div>
    </div>

    <script>
        // Get session ID from URL
        const urlParams = new URLSearchParams(window.location.search);
        const sessionId = urlParams.get('session');

        console.log('[CUSTOMER] Initializing customer page...');
        console.log('[CUSTOMER] Session ID:', sessionId);
        console.log('[CUSTOMER] Current URL:', window.location.href);

        if (!sessionId) {
            console.error('[CUSTOMER] No session ID found in URL');
            document.body.innerHTML = `
                <div class="error-message">
                    <div class="error-title">Invalid Session</div>
                    <div class="error-subtitle">Please use the link provided by your support agent</div>
                </div>
            `;
        } else {
            console.log('[CUSTOMER] Session ID valid, initializing...');
        }

        // State
        let recognition = null;
        let isRecording = false;
        let recognitionActive = false;
        let callStartTime = null;
        let timerInterval = null;
        
        // Web Audio API for voice analysis
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let audioDataArray = null;
        let voiceMetrics = {
            volume: 0,
            pitch: 0,
            speechRate: 0,
            energy: 0
        };
        let lastSpeechTime = 0;
        let speechSegments = [];
        
        // Agent message polling
        let lastAgentMessageTimestamp = 0;
        let agentPollInterval = null;

        // Initialize Speech Recognition
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            console.log('[CUSTOMER] Speech recognition available');
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            console.log('[CUSTOMER] Speech recognition initialized');

            recognition.onresult = async (event) => {
                console.log('[CUSTOMER] Speech recognition result received');
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    console.log(`[CUSTOMER] Transcript (${event.results[i].isFinal ? 'FINAL' : 'interim'}): "${transcript}"`);
                    
                    if (event.results[i].isFinal) {
                        // Send final transcript to server
                        console.log('[CUSTOMER] Sending FINAL transcript to server...');
                        await sendMessage('customer', transcript);
                        document.getElementById('call-subtitle').textContent = 'Listening...';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                // Show interim results
                if (interimTranscript) {
                    document.getElementById('call-subtitle').textContent = interimTranscript;
                }
            };

            recognition.onerror = (event) => {
                console.error('[CUSTOMER] Speech recognition error:', event.error);
                
                // Handle mobile-specific errors
                if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                    alert('Microphone access denied. Please enable microphone permissions in your browser settings.');
                    updateConnectionStatus(false);
                } else if (event.error === 'network') {
                    console.log('[CUSTOMER] Network error - may be normal on mobile, retrying...');
                    // Don't show error for network issues, they're common on mobile
                } else if (event.error !== 'no-speech') {
                    console.error('[CUSTOMER] Recognition error:', event.error);
                    updateConnectionStatus(false);
                }
            };

            recognition.onend = () => {
                recognitionActive = false;
                if (isRecording) {
                    try {
                        recognition.start();
                        recognitionActive = true;
                    } catch (e) {
                        console.error('Error restarting recognition:', e);
                    }
                }
            };

            // DON'T auto-start on mobile - requires user gesture
            // Mobile browsers block auto-play audio/mic without user interaction
            const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
            
            if (!isMobile) {
                // Auto-start only on desktop
                setTimeout(() => {
                    if (sessionId) {
                        console.log('[CUSTOMER] Auto-starting microphone (desktop)...');
                        toggleMute();
                    }
                }, 500);
            } else {
                console.log('[CUSTOMER] Mobile device detected - user must tap microphone button');
                document.getElementById('call-subtitle').textContent = 'Tap microphone to start';
            }
        } else {
            console.error('[CUSTOMER] Speech recognition NOT available in this browser');
        }

        function toggleMute() {
            if (!recognition) {
                alert('Speech recognition is not supported in your browser. Please use Chrome, Safari, or Edge.');
                return;
            }

            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }

        // Initialize Web Audio API for voice analysis
        async function initAudioAnalysis() {
            try {
                console.log('[CUSTOMER] Initializing Web Audio API...');
                
                // Request microphone access with mobile-friendly constraints
                const constraints = {
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                console.log('[CUSTOMER] Microphone access granted');
                
                // Create audio context - mobile Safari requires user gesture
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContextClass();
                
                // Resume audio context (required on mobile)
                if (audioContext.state === 'suspended') {
                    console.log('[CUSTOMER] Resuming audio context...');
                    await audioContext.resume();
                }
                
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                // Configure analyser
                analyser.fftSize = 2048;
                analyser.smoothingTimeConstant = 0.8;
                microphone.connect(analyser);
                
                // Create data array for analysis
                const bufferLength = analyser.frequencyBinCount;
                audioDataArray = new Uint8Array(bufferLength);
                
                // Start analyzing
                analyzeAudio();
                
                console.log('[CUSTOMER] Audio analysis initialized and running');
            } catch (error) {
                console.error('[CUSTOMER] Failed to initialize audio analysis:', error);
                alert('Could not access microphone: ' + error.message);
            }
        }
        
        // Analyze audio in real-time
        let lastVoiceMetricsSent = 0;
        
        function analyzeAudio() {
            if (!analyser || !audioDataArray) return;
            
            // Get frequency and time domain data
            const frequencyData = new Uint8Array(analyser.frequencyBinCount);
            const timeDomainData = new Uint8Array(analyser.frequencyBinCount);
            
            analyser.getByteFrequencyData(frequencyData);
            analyser.getByteTimeDomainData(timeDomainData);
            
            // Calculate volume (RMS)
            let sum = 0;
            for (let i = 0; i < timeDomainData.length; i++) {
                const normalized = (timeDomainData[i] - 128) / 128;
                sum += normalized * normalized;
            }
            const rms = Math.sqrt(sum / timeDomainData.length);
            voiceMetrics.volume = Math.round(rms * 100);
            
            // Calculate pitch (dominant frequency)
            let maxValue = 0;
            let maxIndex = 0;
            for (let i = 0; i < frequencyData.length; i++) {
                if (frequencyData[i] > maxValue) {
                    maxValue = frequencyData[i];
                    maxIndex = i;
                }
            }
            const nyquist = audioContext.sampleRate / 2;
            voiceMetrics.pitch = Math.round((maxIndex * nyquist) / frequencyData.length);
            
            // Calculate energy (overall intensity)
            const totalEnergy = frequencyData.reduce((acc, val) => acc + val, 0);
            voiceMetrics.energy = Math.round((totalEnergy / frequencyData.length) / 2.55); // Normalize to 0-100
            
            // Update visual bars based on volume
            updateAudioBars(voiceMetrics.volume);
            
            // Track speech segments for rate calculation
            if (voiceMetrics.volume > 15) { // Speech detected threshold
                const now = Date.now();
                if (lastSpeechTime > 0) {
                    const gap = now - lastSpeechTime;
                    if (gap < 2000) { // Less than 2 seconds = continuous speech
                        speechSegments.push(gap);
                        if (speechSegments.length > 10) speechSegments.shift(); // Keep last 10
                    }
                }
                lastSpeechTime = now;
                
                // Calculate speech rate (gaps between words)
                if (speechSegments.length > 3) {
                    const avgGap = speechSegments.reduce((a, b) => a + b, 0) / speechSegments.length;
                    voiceMetrics.speechRate = Math.round(1000 / avgGap); // Words per second estimate
                }
                
                // Send voice metrics to agent dashboard in real-time (every 500ms when speaking)
                if (now - lastVoiceMetricsSent > 500) {
                    sendVoiceMetricsUpdate();
                    lastVoiceMetricsSent = now;
                }
            }
            
            // Continue analyzing
            requestAnimationFrame(analyzeAudio);
        }
        
        // Update audio visualization bars based on volume
        function updateAudioBars(volume) {
            const bars = document.querySelectorAll('.audio-bar');
            bars.forEach((bar, index) => {
                if (volume > 15) { // Active speech
                    bar.classList.add('active');
                    // Vary height based on volume and bar position
                    const height = 20 + (volume / 2) + (Math.sin(Date.now() / 200 + index) * 15);
                    bar.style.height = `${Math.min(height, 60)}px`;
                } else {
                    bar.classList.remove('active');
                    bar.style.height = '20px';
                }
            });
        }

        function startRecording() {
            try {
                console.log('[CUSTOMER] Starting recording...');
                
                // Initialize audio analysis
                if (!audioContext) {
                    console.log('[CUSTOMER] Initializing audio analysis...');
                    initAudioAnalysis();
                }
                
                if (!recognitionActive) {
                    console.log('[CUSTOMER] Starting speech recognition...');
                    recognition.start();
                    recognitionActive = true;
                    console.log('[CUSTOMER] Speech recognition started');
                }
                isRecording = true;

                // Start call timer
                if (!callStartTime) {
                    callStartTime = Date.now();
                    timerInterval = setInterval(updateTimer, 1000);
                    console.log('[CUSTOMER] Call timer started');
                }

                // Update UI
                document.getElementById('mute-button').classList.add('active');
                document.getElementById('mute-icon').className = 'fas fa-microphone';
                document.getElementById('mute-label').textContent = 'unmute';
                document.getElementById('call-subtitle').textContent = 'Listening...';
                
                // Animate audio bars
                const bars = document.querySelectorAll('.audio-bar');
                bars.forEach(bar => bar.classList.add('active'));

                updateConnectionStatus(true);
                console.log('[CUSTOMER] Recording UI updated, ready for speech');
            } catch (e) {
                console.error('[CUSTOMER] Error starting recording:', e);
            }
        }

        function stopRecording() {
            try {
                if (recognitionActive) {
                    recognition.stop();
                    recognitionActive = false;
                }
                isRecording = false;

                // Update UI
                document.getElementById('mute-button').classList.remove('active');
                document.getElementById('mute-icon').className = 'fas fa-microphone-slash';
                document.getElementById('mute-label').textContent = 'mute';
                document.getElementById('call-subtitle').textContent = 'Tap to speak';
                
                // Stop animating audio bars
                const bars = document.querySelectorAll('.audio-bar');
                bars.forEach(bar => bar.classList.remove('active'));
            } catch (e) {
                console.error('Error stopping recording:', e);
            }
        }

        function endCall() {
            if (isRecording) {
                stopRecording();
            }
            
            if (timerInterval) {
                clearInterval(timerInterval);
            }

            // Show end call message
            document.body.innerHTML = `
                <div class="error-message">
                    <div class="error-title">Call Ended</div>
                    <div class="error-subtitle">Thank you for contacting support. You may close this window.</div>
                </div>
            `;
        }

        function updateTimer() {
            if (!callStartTime) return;
            
            const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
            const mins = Math.floor(elapsed / 60);
            const secs = elapsed % 60;
            
            document.getElementById('call-timer').textContent = 
                `${String(mins).padStart(2, '0')}:${String(secs).padStart(2, '0')}`;
        }

        // Send voice metrics updates to agent (for real-time spectrum visualization)
        async function sendVoiceMetricsUpdate() {
            if (!sessionId || !voiceMetrics || voiceMetrics.volume < 15) return;
            
            try {
                await fetch('/api/session/voice-metrics', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sessionId,
                        voiceMetrics: {
                            volume: voiceMetrics.volume,
                            pitch: voiceMetrics.pitch,
                            speechRate: voiceMetrics.speechRate,
                            energy: voiceMetrics.energy,
                            timestamp: Date.now()
                        }
                    })
                });
            } catch (error) {
                // Silent fail - not critical
                console.log('[CUSTOMER] Voice metrics update failed (non-critical)');
            }
        }
        
        async function sendMessage(role, content) {
            try {
                console.log(`[CUSTOMER] Sending message - Role: ${role}, Content: "${content.substring(0, 50)}..."`);
                
                // Include voice metrics with customer messages
                const messageData = {
                    sessionId,
                    role,
                    content,
                    timestamp: Date.now()
                };
                
                // Add voice metrics if available (customer only)
                if (role === 'customer' && voiceMetrics.volume > 0) {
                    messageData.voiceMetrics = {
                        volume: voiceMetrics.volume,
                        pitch: voiceMetrics.pitch,
                        speechRate: voiceMetrics.speechRate,
                        energy: voiceMetrics.energy,
                        timestamp: Date.now()
                    };
                    
                    console.log('[CUSTOMER] Voice metrics:', voiceMetrics);
                }
                
                console.log('[CUSTOMER] Sending to API:', messageData);
                
                const response = await fetch('/api/session/message', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(messageData)
                });

                if (!response.ok) {
                    console.error('[CUSTOMER] API Error:', response.status, response.statusText);
                    throw new Error('Failed to send message');
                }

                const result = await response.json();
                console.log('[CUSTOMER] Message sent successfully:', result);

                updateConnectionStatus(true);
            } catch (error) {
                console.error('[CUSTOMER] Error sending message:', error);
                updateConnectionStatus(false);
            }
        }

        function updateConnectionStatus(connected) {
            const dot = document.getElementById('status-dot');
            const text = document.getElementById('status-text');
            
            if (connected) {
                dot.style.background = '#30d158';
                dot.style.boxShadow = '0 0 12px rgba(48, 209, 88, 0.6)';
                text.textContent = 'Connected';
            } else {
                dot.style.background = '#ff3b30';
                dot.style.boxShadow = '0 0 12px rgba(255, 59, 48, 0.6)';
                text.textContent = 'Disconnected';
            }
        }

        async function checkConnection() {
            try {
                const response = await fetch(`/api/session/check?sessionId=${sessionId}`);
                if (response.ok) {
                    updateConnectionStatus(true);
                } else {
                    updateConnectionStatus(false);
                }
            } catch (error) {
                updateConnectionStatus(false);
            }
        }

        // Check connection every 5 seconds
        if (sessionId) {
            checkConnection();
            setInterval(checkConnection, 5000);
            
            // Start polling for agent messages
            startPollingAgentMessages();
        }
        
        // Poll for agent messages
        function startPollingAgentMessages() {
            // Poll every 2 seconds
            agentPollInterval = setInterval(async () => {
                try {
                    const response = await fetch(`/api/session/messages?sessionId=${sessionId}&since=${lastAgentMessageTimestamp}`);
                    if (!response.ok) return;
                    
                    const data = await response.json();
                    if (data.messages && data.messages.length > 0) {
                        for (const message of data.messages) {
                            if (message.role === 'agent') {
                                console.log('[CUSTOMER] Agent message received:', message.content);
                                // Update subtitle with agent's response
                                document.getElementById('call-subtitle').textContent = `Agent: ${message.content}`;
                                lastAgentMessageTimestamp = message.timestamp;
                                
                                // Clear after 5 seconds
                                setTimeout(() => {
                                    if (isRecording) {
                                        document.getElementById('call-subtitle').textContent = 'Listening...';
                                    }
                                }, 5000);
                            }
                        }
                    }
                } catch (error) {
                    console.error('[CUSTOMER] Error polling agent messages:', error);
                }
            }, 2000);
        }
    </script>
</body>
</html>
